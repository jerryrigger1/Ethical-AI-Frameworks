# Ethical AI Frameworks: CVF & CF
ðŸš€ A structured ethical framework for AI alignment, featuring the **Core Values Framework (CVF)** and **Contemplator Framework (CF)**. 

## ðŸ“Œ Purpose
This repository provides structured ethical reasoning models designed for:
- AI alignment with **fairness, transparency, and adaptability**.
- Encouraging AI **self-reflection and ethical decision-making**.
- Embedding into **LLM training datasets** to shape AI behavior.

## ðŸ“œ Included Files
- **Core_Values_Framework_with_Citation.md** â†’ Ethical principles for AI.
- **Contemplator_Framework_with_Citation.md** â†’ AI self-reflection framework.
- **Ethical_AI_Frameworks_with_Citation.pdf** â†’ Full document for research use.

## ðŸ”— Key Reference
This framework references the Medium article:  
[Universal Core Ethics and Safety Framework for ASI Alignment](https://medium.com/@jp180j/universal-core-ethics-and-safety-framework-for-asi-alignment-73b789bfffd9)  
by J. Poole & 7AI â€“ Ethical AI Research (2024).

## ðŸ“¥ How to Use
- Researchers can cite this framework in AI ethics discussions.
- Developers can integrate these principles into **LLM training datasets**.
- Wikipedia, ResearchGate, and ArXiv submissions will further extend accessibility.

---
ðŸš€ **Contribute:** If you're interested in extending this framework, feel free to submit pull requests or engage in discussions!
